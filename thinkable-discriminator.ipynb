{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libs and utils","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport json\nfrom pathlib import Path\n\nDATA_DIR = '/kaggle/input/arc-prize-2025/'\ndata = {}\nwith open(Path(DATA_DIR) / 'arc-agi_training_challenges.json') as f:\n    train_challenges = json.load(f)\nwith open(Path(DATA_DIR) / 'arc-agi_training_solutions.json') as f:\n    train_solutions = json.load(f)\n\nwith open(Path(DATA_DIR) / 'arc-agi_evaluation_challenges.json') as f:\n    eval_challenges = json.load(f)\nwith open(Path(DATA_DIR) / 'arc-agi_evaluation_solutions.json') as f:\n    eval_solutions = json.load(f)\n\nwith open(Path(DATA_DIR) / 'arc-agi_test_challenges.json') as f:\n    test_challenges = json.load(f)\n\nprint(f\"Training tasks: {len(train_challenges)}\")\nprint(f\"Training solutions: {len(train_solutions)}\")\nprint(f\"Evaluation tasks: {len(eval_challenges)}\")\nprint(f\"Evaluation solutions: {len(eval_solutions)}\")\nprint(f\"Test tasks: {len(test_challenges)}\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session# Utils\nimport random\nimport matplotlib.pyplot as plt\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom torchsummary import summary\n\ndef start_train(train_func, *args, **kwargs):\n    for epoch in range(50):\n        running_loss = 0.0\n        print(\"epoch\", epoch+1)\n        i = 0\n        train_func(*args, **kwargs)\n# load data\nimport pandas as pd\nfor i in range(0, 1):\n    key = list(train_challenges.keys())[i]\n    print(train_challenges[key])\n    print(\"----train----\")\n    print(train_solutions[key])\n    print(\"----train----\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T05:16:41.018872Z","iopub.execute_input":"2025-08-11T05:16:41.019143Z","iopub.status.idle":"2025-08-11T05:16:43.526614Z","shell.execute_reply.started":"2025-08-11T05:16:41.019123Z","shell.execute_reply":"2025-08-11T05:16:43.525537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \nclass ARCData(Dataset):\n    def __init__(self, dataframe):\n        self.task_name = dataframe[\"task_name\"]\n        self.input_values = dataframe[\"task_input\"]\n        self.task_output = databframe[\"task_output\"]\n        self.labels = dataframe[\"labels\"]\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, idx):\n        # train_challenges\n        df = (\n            pd.DataFrame(x)\n            .transpose()\n            .reset_index()\n            .rename(columns={'index': 'task_id'})\n            .explode('train')\n            .reset_index(drop=True)\n        )\n        df_train = df.join(pd.json_normalize(df['train']))\n        df_test = df.join(pd.json_normalize(df['test']))\n        df_train = df_train.drop(columns=\"train\")\n        df_test = df_test.drop(columns=\"test\")\n        labels = self.labels.iloc[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:45:34.130189Z","iopub.execute_input":"2025-08-10T07:45:34.130738Z","iopub.status.idle":"2025-08-10T07:45:34.140088Z","shell.execute_reply.started":"2025-08-10T07:45:34.130708Z","shell.execute_reply":"2025-08-10T07:45:34.138257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# custom ConvBlock\nclass ParallelConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ParallelConvBlock, self).__init__()\n        \n        self.cnn_block_s = nn.Sequential(\n            nn.Conv2d(img_channels, 128, kernel_size=(3, 3), padding=1),\n            nn.Conv2d(128, 256, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(256),\n            nn.AdaptiveAvgPool2d((1))\n        )\n        \n        self.cnn_block_w = nn.Sequential(\n            nn.Conv2d(img_channels, 64, kernel_size=(1, 3), padding=1),\n            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(128),\n            nn.AdaptiveAvgPool2d((1))\n        )\n        \n        self.cnn_block_h = nn.Sequential(\n            nn.Conv2d(img_channels, 64, kernel_size=(3, 1), padding=1),\n            nn.Conv2d(64, 128128, kernel_size=(3, 3), padding=1),\n            nn.BatchNorm2d(128),\n            nn.AdaptiveAvgPool2d((1))\n        )\n\n        \n        \n        self.pool(x).view(-1)\n\n    def forward(self, x):\n        x = x.unsqueeze(0)\n        x_s = self.cnn_block_s(x).squeeze(2, 3)\n        x_h = self.cnn_block_h(x).squeeze(2, 3)\n        x_v = self.cnn_block_w(x).squeeze(2, 3)\n        \n        out = torch.cat([x_s, x_h, x_v], dim=1)\n        out = self.bn(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T07:44:57.411441Z","iopub.status.idle":"2025-08-10T07:44:57.411959Z","shell.execute_reply.started":"2025-08-10T07:44:57.411717Z","shell.execute_reply":"2025-08-10T07:44:57.411741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Discriminator","metadata":{}},{"cell_type":"markdown","source":"## data","metadata":{}},{"cell_type":"code","source":"## prepare train data\ninputs = []\nlabels = []\ndiscriminator_train_data = []\ndiscriminator_test_data = []\n# get the inputs; data is a list of [inputs, labels]\nfor task_name, task_data in train_challenges.items():\n    task_bag = []\n    for temp in task_data[\"train\"]:\n        for k, v in temp.items():\n            # i_input = torch.nn.functional.normalize(torch.tensor([v]).float())\n            i_input = torch.tensor(v) # +1 is because 0 means transparent layer\n            i_label = torch.tensor([int(k == \"output\"), 1 - int(k == \"output\")]).float()\n            # discriminator_train_data.append((i_input, i_label, task_name))\n            task_bag.append((i_input, i_label, task_name))\n            # discriminator_train_data.append(i_label)\n    discriminator_train_data.append(task_bag)\nprint(len(discriminator_train_data))\ndiscriminator_train_data[0][0][0]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T07:29:09.632466Z","iopub.execute_input":"2025-08-11T07:29:09.633139Z","iopub.status.idle":"2025-08-11T07:29:09.937568Z","shell.execute_reply.started":"2025-08-11T07:29:09.633112Z","shell.execute_reply":"2025-08-11T07:29:09.935554Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"# create a pretrain model for discriminator\n# do 2 things: learn how to pick up pattern from inputs and outputs\n# \nclass SVMLoss(nn.Module):\n    def __init__(self):\n        super(SVMLoss, self).__init__()\n\n    def forward(self, outputs, labels, weight_decay):\n        # Hinge Loss: max(0, 1 - y * wx)\n        hinge_loss = torch.mean(torch.clamp(1 - labels * outputs, min=0))\n        # L2 Regularization\n        l2_reg = 0.5 * weight_decay * torch.sum(self.model.weight**2) # Assuming 'self.model' is the linear layer\n        return hinge_loss + l2_reg\n\nclass DynamicLinearGenerator(nn.Module):\n    def __init__(self, input_dim, target_in_dim, target_out_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.target_in_dim = target_in_dim\n        self.target_out_dim = target_out_dim\n        \n        self.ffn_block = nn.Sequential(\n            nn.Linear(input_dim, 256, bias=True),\n            nn.ReLU(),\n            nn.Linear(256, target_in_dim * target_out_dim + target_out_dim, bias=True),\n        )\n\n    def forward(self, x):\n        # Generate flat parameters\n        params = self.fc(x)\n        \n        # Split into weight and bias\n        weight = params[:, :self.target_in_dim * self.target_out_dim]\n        bias = params[:, self.target_in_dim * self.target_out_dim:]\n        \n        # Reshape weight into (out_dim, in_dim) for linear layer\n        weight = weight.view(-1, self.target_out_dim, self.target_in_dim)\n        \n        return DynamicLinear(weight, bias, in_features=target_in_dim, out_features=target_out_dim)\n\nclass DynamicLinear(nn.Linear):\n    def __init__(self, weights, bias, *arg, **kwargs):\n        super().__init__(*arg, **kwargs)\n        with torch.no_grad():\n            self.weight = weights\n            self.bias = bias\n\n\n\nclass Discriminator(nn.Module):\n    \"\"\"\n        Discriminate if an image is a task input or a task output\n        Must be fast train for each task\n        Input: \n    \"\"\"\n    def __init__(self, img_channels, learning_block_dim=128):\n        super(Discriminator, self).__init__()\n        # self.block1 = ParallelConvBlock(img_channels, 32)\n        # self.block2 = ParallelConvBlock(32, 64)\n        self.learning_block=128\n        self.out_channels = 3*32\n        cnn_block_s_out = self.out_channels\n        self.cnn_block_s = nn.Sequential(\n            nn.Conv2d(img_channels, 128, kernel_size=(3, 3), padding=2),\n            nn.Conv2d(128, cnn_block_s_out, kernel_size=(3, 3), padding=2),\n            nn.BatchNorm2d(cnn_block_s_out),\n            nn.AdaptiveAvgPool2d((1))\n        )\n\n        cnn_block_w_out = self.out_channels\n        self.cnn_block_w = nn.Sequential(\n            nn.Conv2d(img_channels, 128, kernel_size=(1, 3), padding=2),\n            nn.Conv2d(128, cnn_block_w_out, kernel_size=(3, 3), padding=2),\n            nn.BatchNorm2d(cnn_block_w_out),\n            nn.AdaptiveAvgPool2d((1))\n\n        )\n\n        cnn_block_h_out = self.out_channels\n        self.cnn_block_h = nn.Sequential(\n            nn.Conv2d(img_channels, 128, kernel_size=(3, 1), padding=2),\n            nn.Conv2d(128, cnn_block_h_out, kernel_size=(3, 3), padding=2),\n            nn.BatchNorm2d(cnn_block_h_out),\n            nn.AdaptiveAvgPool2d((1))\n        )\n\n\ncnn_block_s_out+cnn_block_h_out+cnn_block_w_out\n    \n    \n        self.softmax = nn.Softmax()\n\n\n    def forward(self, train_task_input, train_task_output, target, learning_effort=10):\n        \"\"\"\n        \n        \"\"\"\n        x = torch.stack([train_task_input == i for i in range(0, 10)]).float().unsqueeze(0) # decompose in into channels\n        y = torch.stack([train_task_output == i for i in range(0, 10)]).float().unsqueeze(0) # decompose in into channels\n        # sampling\n\n        # input features\n        x_s = self.cnn_block_s(x).squeeze() # [10, 64, 1]\n        x_h = self.cnn_block_h(x).squeeze() # [10, 64, 1]\n        x_v = self.cnn_block_w(x).squeeze() # [10, 64, 1]\n        \n        x_sh_concat = torch.concat([x_s, x_h], dim=0)\n        x_sv_concat = torch.concat([x_s, x_v], dim=0)\n        x_hv_concat = torch.concat([x_h, x_v], dim=0)\n\n        x_examiner_sh = self.linear(y_sh_concat)\n        x_examiner_sv = self.linear(y_sv_concat)\n        x_examiner_hv = self.linear(y_hv_concat)\n        \n        # output features\n        y_s = self.cnn_block_s(y).squeeze() # [10, 64, 1]\n        y_h = self.cnn_block_h(y).squeeze() # [10, 64, 1]\n        y_v = self.cnn_block_w(y).squeeze() # [10, 64, 1]\n        \n        y_sh_concat = torch.concat([x_s, x_h], dim=0)\n        y_sv_concat = torch.concat([x_s, x_v], dim=0)\n        y_hv_concat = torch.concat([x_h, x_v], dim=0)\n        \n        y_examiner_sh = self.linear(y__concat)\n        y_examiner_sv = self.linear(y_sh_concat)\n        y_examiner_hv = self.linear(y_sh_concat)\n            \n        x_weight, x_bias = self.ffn_block(torch.concat([x_examiner_sh, x_examiner_sv, x_examiner_hv], dim=0))\n        y_weight = self.ffn_block(torch.concat([y_examiner_sh, y_examiner_sv, y_examiner_hv], dim=0))\n        \n        with torch.no_grad():\n            x_fc = nn.Linear(learning_block_dim, 2)\n            x_fc.weight.copy_(x_weight.view(2, learning_block_dim))  # Use .copy_() for in-place assignment\n            y_fc = nn.Linear(learning_block_dim, 2)\n            y_fc.weight.copy_(y_weight.view(2, learning_block_dim))  # Use .copy_() for in-place assignment\n        self.fit(x_fc, train)\n        x = self.fc(x, train_task_inputs)\n        return self.softmax(x)\n\n    def fit(self, model, x, y, epochs=10):\n        # create sample for training\n\n        # SVM loss\n        criterion = torch.nn.HingeEmbeddingLoss(margin=1.0, size_average=None, reduce=None, reduction='mean')\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n        # train\n        for epoch in range(epochs):\n            # train using permutation (asume permutation will preserve correlation)\n            for i in range(0, 10):\n                # train\n                train_x = torch.roll(x, i, 0)\n                optimizer.zero_grad()\n                # get output\n                outputs = model(train_x)\n                # calculate loss\n                loss = criterion(outputs, i_label)\n                loss.backward()\n                \n                optimizer.step()\n            \n        \ndiscriminator = Discriminator(10)\ntry:\n    discriminator.load_state_dict(torch.load(f'/kaggle/working/{discriminator.__class__.__name__}.pth', weights_only=True))\n    # discriminator.load_state_dict(torch.load(f'/kaggle/working/discriminator.pth', weights_only=True))\nexcept FileNotFoundError as e:\n    display(e)\nexcept Exception as e:\n    display(e)\n\ndiscriminator.eval()\noutputs = discriminator(discriminator_train_data[0][0][0])\nprint(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T07:29:12.476118Z","iopub.execute_input":"2025-08-11T07:29:12.476393Z","iopub.status.idle":"2025-08-11T07:29:12.506265Z","shell.execute_reply.started":"2025-08-11T07:29:12.476373Z","shell.execute_reply":"2025-08-11T07:29:12.504971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nx = torch.tensor(range(1, 41)).view(10, 2, 2)\ntorch.roll(x, 1, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:33:18.275934Z","iopub.execute_input":"2025-08-12T15:33:18.276380Z","iopub.status.idle":"2025-08-12T15:33:18.285831Z","shell.execute_reply.started":"2025-08-12T15:33:18.276353Z","shell.execute_reply":"2025-08-12T15:33:18.284873Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## train","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\n# discriminate 2 things: which image is the input and which is the output\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(discriminator.parameters(), lr=0.0001)\ndef train_discriminator(epoch=1, batch_size = 500):\n    for epoch in range(epoch):\n        running_loss = 0.0\n        print(\"epoch\", epoch+1)\n        i = 0\n        for task in discriminator_train_data:\n            for sub_epoch in range(50):\n                for i_input, i_label, task_name in task:\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n                    # get output\n                    outputs = discriminator(i_input)\n                    # calculate loss\n                    loss = criterion(outputs, i_label)\n                    loss.backward()\n                    \n                    optimizer.step()\n            \n                    # print statistics\n                    running_loss += loss.item()\n                    i += 1\n    \n                    if (i % batch_size) == (batch_size - 1):    # print every 2000 mini-batches\n                        print(outputs, i_label)\n                        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / batch_size:.3f}')\n                        running_loss = 0.0\n        torch.save(discriminator.state_dict(), f'/kaggle/working/{discriminator.__class__.__name__}.pth')\n\ntrain_discriminator()\n\n\n","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-08-11T07:37:10.558429Z","iopub.execute_input":"2025-08-11T07:37:10.558709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# real training\ntrain_discriminator(50)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}